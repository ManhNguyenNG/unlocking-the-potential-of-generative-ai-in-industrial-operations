{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a2dc79-6b2d-4539-aa02-6c9c0651e8f5",
   "metadata": {},
   "source": [
    "## Notebook to add NLQ Python examples as embedding to OpenSearch index\n",
    "\n",
    "#### Author: Julia Hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7499d7-9738-4188-ac72-032a9801eb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193ced0",
   "metadata": {},
   "source": [
    "### Before you start working on this notebook, please create opensearch index with proper metadata. The metadata needs to contain one vectorfield. Metadata can be filters: such as source, page, etc. To understand your document input metadata, please print out the sample doc after Langchain textsplitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdab6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U opensearch-py==2.3.1 langchain==0.0.309 \"pypdf>=3.8,<4\" \\\n",
    "    apache-beam \\\n",
    "    datasets \\\n",
    "    tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5b060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffd71b-cd47-47d1-afb7-d54fe3ae3483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install requests_aws4auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea4475-68af-4b71-8de2-8d2d4a434dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import boto3\n",
    "import botocore\n",
    "import time\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89076d-bd4c-41e3-951b-ed4c1628f7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def get_cfn_outputs(stackname: str) -> str:\n",
    "    cfn = boto3.client('cloudformation')\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "def printmd(string: str):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ba829-66ba-4963-b7d3-419d0907297e",
   "metadata": {},
   "source": [
    "## Get parameters from CFN stack\n",
    "## Please replace the CFN stack name to the CFN stack name you used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d0d11-9ee1-4040-9320-98858502ef89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFN_STACK_NAME = \"genai-sagemaker\"\n",
    "outputs = get_cfn_outputs(CFN_STACK_NAME)\n",
    "# global constants\n",
    "service = 'aoss'\n",
    "region = outputs[\"Region\"]\n",
    "aoss_collection_arn = outputs['CollectionARN']\n",
    "aoss_host = f\"{os.path.basename(aoss_collection_arn)}.{region}.aoss.amazonaws.com\"\n",
    "aoss_vector_index = outputs['AOSSVectorIndexName']\n",
    "print(f\"aoss_collection_arn={aoss_collection_arn}\\naoss_host={aoss_host}\\naoss_vector_index={aoss_vector_index}\\naws_region={region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0bf06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the client using the default credential configuration.\n",
    "# You can use the CLI and run 'aws configure' to set access key, secret\n",
    "# key, and default region.\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, service, session_token=credentials.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15987420-7241-45b2-8a61-413fed9af583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build the OpenSearch client\n",
    "client_opensearch = OpenSearch(\n",
    "        hosts=[{'host': aoss_host, 'port': 443}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=300\n",
    "    )\n",
    "\n",
    "index_body = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"vector_field\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1536,\n",
    "         \"method\": {\n",
    "     \"name\":\"hnsw\",\n",
    "     \"space_type\": \"l2\",\n",
    "     \"engine\": \"faiss\"}\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create index\n",
    "response = client_opensearch.indices.create(str(aoss_vector_index), body=index_body)\n",
    "print('\\nCreating index:')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1840676",
   "metadata": {},
   "source": [
    "## If the above cell run into 403 errors, it may due to collection is still in the process of creation, please wait a few minutes and re-run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ccb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bedrock client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.load.dump import dumps\n",
    "from langchain.load.dump import dumpd\n",
    "\n",
    "# - Use the Anthropic Model\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\", client=bedrock_runtime, model_kwargs={\"max_tokens_to_sample\": 200}\n",
    ")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_runtime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0983ee",
   "metadata": {},
   "source": [
    "## start to build the embeding doc in YAML format with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df430fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the YAML module for use in our script\n",
    "import yaml\n",
    "\n",
    "# Opens the file ex1.yaml, and loads the contents in the variable 'result'\n",
    "with open('../data/iot_nlq_sample.yml') as f:\n",
    "    examples =  yaml.safe_load(f)\n",
    "\n",
    "keys = list(examples.keys())\n",
    "print(keys)\n",
    "print(examples['example1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa01ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Output of Split Document\n",
    "example_stri = [''] * len(keys)\n",
    "print(example_stri)\n",
    "for i in range(len(keys)):\n",
    "    key = str(keys[i])\n",
    "    for k, val in examples[key].items():\n",
    "        example_stri[i] += k + ':' + val + ' '\n",
    "        \n",
    "for i in range(len(example_stri)):\n",
    "    print(\"---------------------------------------\")\n",
    "    print(example_stri[i])\n",
    "    print(len(example_stri[i]))\n",
    "    print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00739b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    sample_embedding = np.array(bedrock_embeddings.embed_query(example_stri[0]))\n",
    "    modelId = bedrock_embeddings.model_id\n",
    "    print(\"Embedding model Id :\", modelId)\n",
    "    print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "    print(\"Size of the embedding: \", sample_embedding.shape)\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "#########This is the same index as it is shown in the Readme. If you want to name it differently, just ensure it is the same name as your OpenSearch index name\n",
    "index_name = aoss_vector_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6be6b2",
   "metadata": {},
   "source": [
    "### Here is where the records will be written to OpenSearch to build the index###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Replace AWS region and host name#############################\n",
    "region = 'us-east-1'\n",
    "host = aoss_host +':443'\n",
    "service = 'aoss'\n",
    "\n",
    "textsearch = OpenSearchVectorSearch.from_texts(\n",
    "    example_stri,\n",
    "    bedrock_embeddings,\n",
    "    opensearch_url=host,\n",
    "    http_auth=awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    index_name=aoss_vector_index,\n",
    "    engine=\"faiss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d222104-8f1e-4d2e-a30b-bd9927b53748",
   "metadata": {},
   "source": [
    "## Test the embedding with a sample question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca292ad6-6ce8-43c5-a00a-7825fe1b808f",
   "metadata": {},
   "source": [
    "## If the query below does not work, it may due to the new index record ingestion time, please wait a few minutes and retry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"tell me the total number of unique sensorname, and provide the answer in one sentence\"\n",
    "\n",
    "results = textsearch.similarity_search(query, k=3)  # our search query  # return 3 most relevant docs\n",
    "print(dumps(results, pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351f126-1abc-4ebc-8132-39b3f776a663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
